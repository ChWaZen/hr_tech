{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##自傳內容\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import os\n",
    "from opencc import OpenCC\n",
    "import numpy as np\n",
    "import ast\n",
    "import jieba\n",
    "from datetime import datetime\n",
    "import re\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tabula import read_pdf\n",
    "import PyPDF2\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "def extract_text_with_keyword(pdf_path, keyword, keyword2):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if keyword in page_text:\n",
    "                    index_keyword = page_text.find(keyword)\n",
    "                    index_keyword2 = page_text.find(keyword2, index_keyword)\n",
    "                    if index_keyword2 != -1:\n",
    "                        extracted_text = page_text[index_keyword2 + len(keyword2):]\n",
    "                        # Find the last period in the extracted text\n",
    "                        last_period_index = extracted_text.rfind(\"。\")\n",
    "                        if last_period_index != -1:\n",
    "                            extracted_text = extracted_text[:last_period_index+1]  # Include the last period\n",
    "                        return extracted_text.strip()  # Remove leading/trailing whitespace\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "def process_pdfs_in_folder(folder_path, keyword, keyword2):\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            id_column = filename[:10]  # Extract first 10 characters of filename\n",
    "\n",
    "            # Extract text containing keyword\n",
    "            extracted_text = extract_text_with_keyword(pdf_path, keyword, keyword2)\n",
    "            \n",
    "            data.append({\"id\": id_column, \"intro\": extracted_text or \"No text extracted\"})\n",
    "\n",
    "    return data\n",
    "\n",
    "keyword = \"自傳內容\"\n",
    "keyword2 = \"---------------------------------------------------------------------\"\n",
    "output_csv = '自傳.csv'\n",
    "\n",
    "# Specify the folder paths containing PDFs\n",
    "folder_paths = [\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "# Process PDFs in the specified folders and combine the results\n",
    "combined_data = []\n",
    "for folder_path in folder_paths:\n",
    "    data = process_pdfs_in_folder(folder_path, keyword,keyword2)\n",
    "    combined_data.extend(data)\n",
    "\n",
    "# Create DataFrame from combined data\n",
    "df = pd.DataFrame(combined_data)\n",
    "df = df.drop_duplicates(subset=df.columns[0], keep='first')\n",
    "# Write DataFrame to CSV\n",
    "df.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A123456789: 第 1 頁 - 覆蓋原本的 CSV 檔案 (履歷)\n",
      "A123456789: 第 1 頁 - 儲存為 CSV 檔案 (履歷)\n",
      "A123456789: 第 1 頁 - 跳過 (無內容)\n",
      "A123456789: 第 2 頁 - 跳過 (無內容)\n",
      "B123456789: 第 1 頁 - 覆蓋原本的 CSV 檔案 (履歷)\n",
      "B123456789: 第 1 頁 - 儲存為 CSV 檔案 (履歷)\n",
      "B123456789: 第 1 頁 - 跳過 (無內容)\n",
      "B123456789: 第 2 頁 - 跳過 (無內容)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def is_standard_resume_page(text):\n",
    "    # Add keywords or patterns related to \"制式招募履歷表\"\n",
    "    keywords = [\"甄才類別\", \"standard recruitment resume\"]\n",
    "    return any(keyword in text for keyword in keywords)\n",
    "\n",
    "def contains_job_description(text):\n",
    "    # Check if the text contains \"職務與工作內容\"\n",
    "    return \"職務與工作內容\" in text\n",
    "\n",
    "def extract_page_content(pdf_path, page_number, filename, output_folder):\n",
    "    # Try to read tables from the PDF\n",
    "    dfs = read_pdf(pdf_path, pages=page_number, lattice=True, multiple_tables=True)\n",
    "    \n",
    "    if dfs and not dfs[0].empty:  # If tables are found\n",
    "        # Concatenate the dataframes\n",
    "        concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        # Check the number of rows in the dataframe\n",
    "        num_rows = len(concatenated_df)\n",
    "\n",
    "        # Determine whether to save the CSV file or not based on the number of rows\n",
    "        if num_rows < 10:\n",
    "            print(f\"{filename}: 第 {page_number} 頁 - 不儲存，因為行數小於10\")\n",
    "            return\n",
    "\n",
    "\n",
    "        else:\n",
    "           # Find the existing CSV file\n",
    "            csv_file = os.path.join(output_folder, f\"{filename}履歷.csv\")\n",
    "\n",
    "            # Check if the CSV file already exists\n",
    "            if os.path.exists(csv_file):\n",
    "                # Read the existing CSV file to compare the number of rows\n",
    "                existing_df = pd.read_csv(csv_file)\n",
    "\n",
    "                # Check the number of rows in the existing CSV file\n",
    "                existing_num_rows = len(existing_df)\n",
    "\n",
    "                # Check the number of rows in the current DataFrame\n",
    "                current_num_rows = len(concatenated_df)\n",
    "\n",
    "                if current_num_rows > existing_num_rows:\n",
    "                    # Overwrite the existing CSV file\n",
    "                    concatenated_df.to_csv(csv_file, index=False, header=False)\n",
    "                    print(f\"{filename}: 第 {page_number} 頁 - 覆蓋原本的 CSV 檔案 (履歷)\")\n",
    "                else:\n",
    "                    print(f\"{filename}: 第 {page_number} 頁 - 跳過 (行數不多於原本的 CSV 檔案)\")\n",
    "\n",
    "        # Save the CSV file\n",
    "        concatenated_df.to_csv(csv_file, index=False, header=False)\n",
    "        print(f\"{filename}: 第 {page_number} 頁 - 儲存為 CSV 檔案 (履歷)\")\n",
    "\n",
    "    \n",
    "    # If no content found\n",
    "    return f\"{filename}: 第 {page_number} 頁 - 跳過 (無內容)\"\n",
    "\n",
    "def process_first_five_pdfs(folder_path, output_folder):\n",
    "    # Get the first five PDF files in the specified folder\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith(\".pdf\")]\n",
    "\n",
    "    # Process each of the first five PDFs\n",
    "    for filename in pdf_files:\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        reader = PyPDF2.PdfReader(pdf_path)\n",
    "        total_pages = len(reader.pages)\n",
    "\n",
    "        # Iterate through each page of the PDF\n",
    "        for page_number in range(1, total_pages + 1):\n",
    "            result = extract_page_content(pdf_path, page_number, os.path.splitext(filename)[0], output_folder)\n",
    "            print(result)\n",
    "\n",
    "# Specify the folder paths\n",
    "folder_path = ''\n",
    "output_folder = ''\n",
    "\n",
    "# Process the first five PDFs in the specified folder and save CSVs in the output folder\n",
    "process_first_five_pdfs(folder_path, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test          id                                                edu  \\\n",
      "0   cv  A123456789  [[X大學, 財金系(日間部), 畢業, 自2014年9月至2018年6月], [T高中, ...   \n",
      "1   cv  B123456789  [[T大學, 企管/夜, 畢業, 自1998年9月至2001年7月], [Y商工, 電機/日...   \n",
      "\n",
      "                                   language_ability  \\\n",
      "0  測驗名稱:___多益______________測驗成績:_____600___________   \n",
      "1                測驗名稱:                        測驗成績:   \n",
      "\n",
      "                                          experience  \\\n",
      "0  [[Y銀行, 初辦, 存匯/放款/支存, 自2022年9月至2023年9月], [S銀行, ...   \n",
      "1  [[Y銀行, 初辦, 存匯/放款, 自2018年10月至2018年11月], [T銀行, 中...   \n",
      "\n",
      "                                             license  \n",
      "0  [人身保險業務員, 銀行內部控制與內部稽核, 投資型保險商品概要、金融體系概述, 財產保險業...  \n",
      "1                                                 []  \n",
      "  test          id                                                edu  \\\n",
      "0   cv  A123456789  [[X大學, 財金系(日間部), 畢業, 自2014年9月至2018年6月], [T高中, ...   \n",
      "1   cv  B123456789  [[T大學, 企管/夜, 畢業, 自1998年9月至2001年7月], [Y商工, 電機/日...   \n",
      "\n",
      "                                   language_ability  \\\n",
      "0  測驗名稱:___多益______________測驗成績:_____600___________   \n",
      "1                測驗名稱:                        測驗成績:   \n",
      "\n",
      "                                          experience  \\\n",
      "0  [[Y銀行, 初辦, 存匯/放款/支存, 自2022年9月至2023年9月], [S銀行, ...   \n",
      "1  [[Y銀行, 初辦, 存匯/放款, 自2018年10月至2018年11月], [T銀行, 中...   \n",
      "\n",
      "                                             license  \\\n",
      "0  [人身保險業務員, 銀行內部控制與內部稽核, 投資型保險商品概要、金融體系概述, 財產保險業...   \n",
      "1                                                 []   \n",
      "\n",
      "                                               intro  \n",
      "0  我誠摯地向貴行遞交我的應徵申請，表達我對銀行業務的熱情及對這個職位的興\\n趣。我是一名專業、...  \n",
      "1  我希望能成為貴行的一員，貢獻我的技能和熱情。作為一名有豐富銀行業務經\\n驗的應聘者，我深信我...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "############################ 撈出資料 ###################### \n",
    "def clean_items(items):\n",
    "    clean_items = [item.replace(' ', '').replace('\\r', '').replace('\\n', '').replace('(最高)', '').replace('(次高)', '') for item in items if isinstance(item, str) and '專業證照' not in item]\n",
    "    clean_items = [x if x != \"\" else None for x in clean_items]\n",
    "    return clean_items\n",
    "\n",
    "def extract_and_clean_data(data, resume_row, keyword_1, keyword_2, length):\n",
    "    data_section = []  \n",
    "    while keyword_1 not in str(resume_row):\n",
    "        resume_row = next(resume_tuples)\n",
    "    resume_row = next(resume_tuples)  # 获取 '學歷背景' 下一行的数据\n",
    "\n",
    "    while keyword_2 not in str(resume_row):\n",
    "        data_section.append(resume_row)\n",
    "        resume_row = next(resume_tuples)\n",
    "\n",
    "    for s in data_section:\n",
    "    # Check if s[0] is a number and not NaN\n",
    "        if isinstance(s[1], str):\n",
    "            data.extend(clean_items(s))\n",
    "\n",
    "    data.extend([''] * (length - len(data)))\n",
    "    return data, resume_row\n",
    "\n",
    "\n",
    "all_data = []\n",
    "directory_path_name = ['']\n",
    "for path in directory_path_name:\n",
    "    file_names = os.listdir(f'{path}')\n",
    "\n",
    "    resume_names = [i for i in file_names if \"履歷\" in i]\n",
    "\n",
    "    for name in resume_names:\n",
    "        resume_df = pd.read_csv(f'{path}/{name}', header=None)\n",
    "        resume_tuples = resume_df.itertuples(index=False, name=None)\n",
    "\n",
    "        data = [f'{name[:10]}']\n",
    "        data.append(f'{path}')\n",
    "        licience = []\n",
    "        try:\n",
    "            resume_row = None\n",
    "            data, resume_row = extract_and_clean_data(data, resume_row, '學歷背景', '工作經驗', 10)\n",
    "            data, resume_row = extract_and_clean_data(data, resume_row, '工作經驗', '外語能力', 26)\n",
    "\n",
    "            data.append(resume_row[1]) # 外語能力\n",
    "\n",
    "            while '專業證照' not in str(resume_row):\n",
    "                resume_row = next(resume_tuples)\n",
    "            \n",
    "            licience = []\n",
    "\n",
    "            while True:\n",
    "                licience.extend(resume_row)\n",
    "                resume_row = next(resume_tuples)\n",
    "\n",
    "\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        data.append(clean_items(licience))\n",
    "        all_data.append(data)\n",
    "\n",
    "# Convert the list of lists to a DataFrame\n",
    "result_df = pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "# 定义转换函数，将所有的民国年转换为公元年\n",
    "def convert_minguo_to_ad(date_range_str):\n",
    "    import re\n",
    "    # 确保输入是字符串类型\n",
    "    if not isinstance(date_range_str, str):\n",
    "        return date_range_str  # 如果不是字符串，直接返回原值\n",
    "    \n",
    "    # 查找所有的年份\n",
    "    matches = re.findall(r'(\\d+)年', date_range_str)\n",
    "    \n",
    "    # 对每一个匹配的年份进行检查和可能的转换\n",
    "    for match in matches:\n",
    "        if len(match) < 4:  # 如果年份长度小于4位数，视为民国年份\n",
    "            ad_year = str(int(match) + 1911)  # 民国年转公元年\n",
    "            date_range_str = date_range_str.replace(match + '年', ad_year + '年', 1)\n",
    "    return date_range_str\n",
    "\n",
    "# 应用转换函数到DataFrame的指定列\n",
    "result_df.iloc[:, 5] = result_df.iloc[:, 5].apply(convert_minguo_to_ad)\n",
    "result_df.iloc[:, 9] = result_df.iloc[:, 9].apply(convert_minguo_to_ad)\n",
    "result_df.iloc[:, 13] = result_df.iloc[:, 13].apply(convert_minguo_to_ad)\n",
    "result_df.iloc[:, 17] = result_df.iloc[:, 17].apply(convert_minguo_to_ad)\n",
    "result_df.iloc[:, 21] = result_df.iloc[:, 21].apply(convert_minguo_to_ad)\n",
    "result_df.iloc[:, 25] = result_df.iloc[:, 25].apply(convert_minguo_to_ad)\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "#####################   轉成繁體中文  ########################\n",
    "\n",
    "# 創建簡繁轉換器\n",
    "cc = OpenCC('s2twp')  # 簡體中文轉換為繁體中文（台灣標準）\n",
    "\n",
    "# 將 merged_df 中的所有欄位的每個值進行簡繁轉換\n",
    "def convert_cell(x):\n",
    "    if isinstance(x, list):\n",
    "        return [cc.convert(str(item)) for item in x]\n",
    "    elif isinstance(x, str):\n",
    "        return cc.convert(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "result_df = result_df.applymap(convert_cell)\n",
    "#############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################ 整理履歷欄位 ###################### \n",
    "\n",
    "# Drop duplicate rows based on the first column (index 0)\n",
    "result_df = result_df.drop_duplicates(subset=result_df.columns[0], keep='first')\n",
    "# Create a new column containing the lists from the first four columns\n",
    "result_df['33'] = result_df.apply(lambda row: row[2:6].tolist(), axis=1)\n",
    "result_df['34'] = result_df.apply(lambda row: row[6:10].tolist(), axis=1)\n",
    "result_df['35'] = result_df.apply(lambda row: row[10:14].tolist(), axis=1)\n",
    "result_df['36'] = result_df.apply(lambda row: row[14:18].tolist(), axis=1)\n",
    "result_df['37'] = result_df.apply(lambda row: row[18:22].tolist(), axis=1)\n",
    "result_df['38'] = result_df.apply(lambda row: row[22:25].tolist(), axis=1)\n",
    "result_df['edu'] = result_df.apply(lambda row: row[28:30].tolist(), axis=1)\n",
    "result_df['experience'] = result_df.apply(lambda row: row[30:34].tolist(), axis=1)\n",
    "result_df = result_df.drop(result_df.columns[2:26], axis=1)\n",
    "result_df = result_df.drop(result_df.columns[4:10], axis=1)\n",
    "\n",
    "\n",
    "# Rename columns\n",
    "result_df = result_df.rename(columns={result_df.columns[0]: 'id',\n",
    "                                      result_df.columns[1]: 'test',\n",
    "                                      result_df.columns[2]: 'language_ability',\n",
    "                                      result_df.columns[3]: 'license'})\n",
    "\n",
    "# Reorder the columns to have the desired order\n",
    "result_df = result_df[['test','id', 'edu', 'language_ability', 'experience', 'license']]\n",
    "print(result_df)\n",
    "####################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################加入額外寫的工作經歷#############################\n",
    "\n",
    "def work_exp_data(resume_row):\n",
    "    work_exp = []\n",
    "    data_section = []  \n",
    "    while '服務機構' not in str(resume_row):\n",
    "        resume_row = next(resume_tuples)\n",
    "    resume_row = next(resume_tuples)  # 获取 '學歷背景' 下一行的数据\n",
    "\n",
    "    while '合計年資' not in str(resume_row):\n",
    "        data_section.append(resume_row)\n",
    "        resume_row = next(resume_tuples)\n",
    "    data_section.append(resume_row)\n",
    "\n",
    "    for w in data_section:\n",
    "        # Check if the elements in w is not NaN\n",
    "        w = [str(x).replace(' ', '').replace('\\r', '').replace('\\n', '') for x in w if x == x]\n",
    "        if len(w) == 7:\n",
    "            work_exp.extend(w[1: 8])\n",
    "        elif '合計年資' in w:\n",
    "            desired_length = 60\n",
    "            if len(work_exp) < desired_length:\n",
    "                # 如果长度小于60，添加空字符串\n",
    "                work_exp.extend([''] * (desired_length - len(work_exp)))\n",
    "            elif len(work_exp) > desired_length:\n",
    "                # 如果长度大于42，截断到前20个元素\n",
    "                work_exp = work_exp[:desired_length]\n",
    "\n",
    "            work_exp.append(w[1])\n",
    "        else:\n",
    "            work_exp.extend([''] * 6)\n",
    "\n",
    "    return work_exp\n",
    "\n",
    "all_data = []\n",
    "directory_path_name = ['']\n",
    "for path in directory_path_name:\n",
    "    file_names = os.listdir(f'{path}')\n",
    "\n",
    "    resume_names = [i for i in file_names if \"工作經歷\" in i]\n",
    "    \n",
    "    for name in resume_names:\n",
    "\n",
    "        data = [f'{name[:10]}']\n",
    "        work_exp_df = pd.read_csv(f'{path}/{name}', header=None)\n",
    "        resume_tuples = work_exp_df.itertuples(index=False, name=None)\n",
    "\n",
    "        resume_row = next(resume_tuples)\n",
    "\n",
    "        try:\n",
    "            data.extend(work_exp_data(resume_row))\n",
    "        except StopIteration:\n",
    "            pass\n",
    "\n",
    "        all_data.append(data)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################加入自傳##########################\n",
    "df3 = pd.read_csv('自傳.csv')\n",
    "merged_df = pd.merge(result_df , df3[['id', \"intro\"]], on='id', how='left')\n",
    "print(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fbp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
