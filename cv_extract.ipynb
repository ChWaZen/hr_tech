{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pdfplumber\n",
        "!pip install opencc-python-reimplemented\n",
        "!pip install tabula-py\n",
        "!pip install PyPDF2\n",
        "!pip install fitz\n",
        "!pip install pytesseract\n",
        "!pip install frontend"
      ],
      "metadata": {
        "id": "WmSXyiHnD4Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pdfplumber\n",
        "from io import BytesIO\n",
        "import csv\n",
        "import pandas as pd\n",
        "from opencc import OpenCC\n",
        "import numpy as np\n",
        "import ast\n",
        "import jieba\n",
        "from datetime import datetime\n",
        "import re\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from tabula import read_pdf\n",
        "import PyPDF2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io"
      ],
      "metadata": {
        "id": "-Q2xDATAJxlB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_pdf('A123456789.pdf', lattice=True, multiple_tables=True)"
      ],
      "metadata": {
        "id": "TqgZ0_Y9a0jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_autobio(pdf_file_name, keyword, keyword2):\n",
        "  with pdfplumber.open(pdf_file_name) as pdf:\n",
        "      for page in pdf.pages:\n",
        "          page_text = page.extract_text()\n",
        "          if keyword in page_text:\n",
        "              index_keyword = page_text.find(keyword)\n",
        "              index_keyword2 = page_text.find(keyword2, index_keyword)\n",
        "              if index_keyword2 != -1:\n",
        "                  extracted_text = page_text[index_keyword2 + len(keyword2):]\n",
        "                  # Find the last period in the extracted text\n",
        "                  last_period_index = extracted_text.rfind(\"。\")\n",
        "                  if last_period_index != -1:\n",
        "                      extracted_text = extracted_text[:last_period_index+1]  # Include the last period\n",
        "                  return extracted_text.strip()  # Remove leading/trailing whitespace\n",
        "\n",
        "def extract_table(pdf_file_name):\n",
        "  # Try to read tables from the PDF\n",
        "  dfs = read_pdf(pdf_file_name, lattice=True, multiple_tables=True)\n",
        "  concatenated_df = pd.concat(dfs, ignore_index=True)\n",
        "  return concatenated_df\n",
        "\n",
        "\n",
        "keyword = \"自傳內容\"\n",
        "keyword2 = \"---------------------------------------------------------------------\""
      ],
      "metadata": {
        "id": "Mumph9SGFdKI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_autobio('A123456789.pdf', keyword, keyword2)"
      ],
      "metadata": {
        "id": "PcMzzjVmV00i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_autobio('B123456789.pdf', keyword, keyword2)"
      ],
      "metadata": {
        "id": "LvxiAlIdWydb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_table('A123456789.pdf')"
      ],
      "metadata": {
        "id": "Ma1nhpj5V2ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_table('B123456789.pdf')"
      ],
      "metadata": {
        "id": "5KMHqo6PWYm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_items(items):\n",
        "    clean_items = [item.replace(' ', '').replace('\\r', '').replace('\\n', '').replace('(最高)', '').replace('(次高)', '') for item in items if isinstance(item, str) and '專業證照' not in item]\n",
        "    clean_items = [x if x != \"\" else None for x in clean_items]\n",
        "    return clean_items\n",
        "\n",
        "def extract_and_clean_data(data, resume_row, keyword_1, keyword_2, length):\n",
        "    data_section = []\n",
        "    while keyword_1 not in str(resume_row):\n",
        "        resume_row = next(resume_tuples)\n",
        "    resume_row = next(resume_tuples)\n",
        "\n",
        "    while keyword_2 not in str(resume_row):\n",
        "        data_section.append(resume_row)\n",
        "        resume_row = next(resume_tuples)\n",
        "\n",
        "    for s in data_section:\n",
        "    # Check if s[0] is a number and not NaN\n",
        "        if isinstance(s[1], str):\n",
        "            data.extend(clean_items(s))\n",
        "\n",
        "    data.extend([''] * (length - len(data)))\n",
        "    return data, resume_row"
      ],
      "metadata": {
        "id": "Ig1FPMO3P9OR"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################ 撈出資料 ######################\n",
        "all_data = []\n",
        "\n",
        "for name in ['A123456789.pdf', 'B123456789.pdf']:\n",
        "  resume_df = extract_table(name)\n",
        "  resume_tuples = resume_df.itertuples(index=False, name=None)\n",
        "\n",
        "  data = [name]\n",
        "  licience = []\n",
        "  try:\n",
        "      resume_row = None\n",
        "      data, resume_row = extract_and_clean_data(data, resume_row, '學歷背景', '工作經驗', 10)\n",
        "      data, resume_row = extract_and_clean_data(data, resume_row, '工作經驗', '外語能力', 26)\n",
        "\n",
        "      data.append(resume_row[1]) # 外語能力\n",
        "\n",
        "      while '證照' not in str(resume_row):\n",
        "          resume_row = next(resume_tuples)\n",
        "\n",
        "      licience = []\n",
        "\n",
        "      while True:\n",
        "          licience.extend(resume_row)\n",
        "          resume_row = next(resume_tuples)\n",
        "\n",
        "\n",
        "  except StopIteration:\n",
        "      pass\n",
        "  data.append(clean_items(licience))\n",
        "  data.append(extract_autobio(name, keyword, keyword2))\n",
        "  all_data.append(data)\n",
        "\n",
        "# Convert the list of lists to a DataFrame\n",
        "result_df = pd.DataFrame(all_data)\n",
        "result_df.to_csv('output.csv', index=False)"
      ],
      "metadata": {
        "id": "oK1RQXafQ0al"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fbp_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}